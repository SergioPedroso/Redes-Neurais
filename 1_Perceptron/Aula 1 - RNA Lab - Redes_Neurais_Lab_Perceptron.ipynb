{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMsuGPnY024WDTuORjBhbQi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SergioPedroso/Mestrado-Sistemas-Inteligentes/blob/main/Aula_3_Redes_Neurais_Lab_Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perceptron - Função Lógica AND**"
      ],
      "metadata": {
        "id": "FILG8CbLOR6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa a biblioteca numpy para a manipulação de arrays e matrizes, devido à melhor eficiência da bilbioteca\n",
        "import numpy as np\n",
        "\n",
        "## DECLARAÇÃO DA FUNÇÃO\n",
        "# Cria o perceptron\n",
        "def yperceptron(W,b,X):\n",
        "  # Calcula a função aditiva, multiplicando a matriz de peso (W) pela matriz de entradas\n",
        "  u = np.dot(W,X) + b\n",
        "  # Loop for para percorrer a matriz e aplicar a função de ativação, neste caso sendo a função degrau/limiar\n",
        "  for i in range(u.shape[1]):\n",
        "      if u[0, i] >= 0:\n",
        "          u[0, i] = 1\n",
        "      else:\n",
        "          u[0, i] = 0\n",
        "  return u\n",
        "\n",
        "## DECLARAÇÃO DAS VARIÁVEIS\n",
        "# A variável X é a matriz com as entradas do Perceptron\n",
        "X = np.array([[0,1,0,1],[0,0,1,1]])\n",
        "print('Número de linhas de X = ',X.shape[0])\n",
        "print('Número de colunas de X = ',X.shape[1])\n",
        "# A variável W é a matriz com os pesos do Perceptron\n",
        "W = np.array([[0.4,0.4]])\n",
        "# A variável b é o bias, que tem o objetivo variar a influência das entradas\n",
        "b = -0.6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6d4b57d-7604-4403-d60e-557b4dc614d6",
        "id": "mpm-EtK2OR6p"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de linhas de X =  2\n",
            "Número de colunas de X =  4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cálculo da saída do Perceptron\n",
        "y = yperceptron(W,b,X)\n",
        "print(y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bacd7c4c-3eba-4609-b124-8c43b123c895",
        "id": "z9FhVbWOOR6r"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2l_eWYwNOkCT",
        "outputId": "ccccf4ab-f916-4689-e7c5-83ee26acaaf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.6"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W"
      ],
      "metadata": {
        "id": "AZdaLckIPlpW",
        "outputId": "b863fc9e-d418-4173-dc7d-99999d978fb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.4, 0.4]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "id": "qXkG3X5EPmfT",
        "outputId": "bfd9f1a5-7d8f-4f62-b590-70ca2fe92ad7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 1],\n",
              "       [0, 0, 1, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Perceptron - Função Lógica OR**"
      ],
      "metadata": {
        "id": "Yy_XF6TJD4jF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importa a biblioteca numpy para a manipulação de arrays e matrizes, devido à melhor eficiência da bilbioteca\n",
        "import numpy as np\n",
        "\n",
        "## DECLARAÇÃO DA FUNÇÃO\n",
        "# Cria o perceptron\n",
        "def yperceptron(W,b,X):\n",
        "  # Calcula a função aditiva, multiplicando a matriz de peso (W) pela matriz de entradas\n",
        "  u = np.dot(W,X) + b\n",
        "  # Loop for para percorrer a matriz e aplicar a função de ativação, neste caso sendo a função degrau/limiar\n",
        "  for i in range(u.shape[1]):\n",
        "      if u[0, i] >= 0:\n",
        "          u[0, i] = 1\n",
        "      else:\n",
        "          u[0, i] = 0\n",
        "  return u\n",
        "\n",
        "## DECLARAÇÃO DAS VARIÁVEIS\n",
        "# A variável X é a matriz com as entradas do Perceptron\n",
        "X = np.array([[0,1,0,1],[0,0,1,1]])\n",
        "print('Número de linhas de X = ',X.shape[0])\n",
        "print('Número de colunas de X = ',X.shape[1])\n",
        "# A variável W é a matriz com os pesos do Perceptron\n",
        "W = np.array([[0.4,0.4]])\n",
        "# A variável b é o bias, que tem o objetivo variar a influência das entradas\n",
        "b = -0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXNDS3cyAyHW",
        "outputId": "e49fc980-f34e-45b4-ad90-8d651ce77fc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de linhas de X =  2\n",
            "Número de colunas de X =  4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cálculo da saída do Perceptron\n",
        "y = yperceptron(W,b,X)\n",
        "print(y)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGwwgHV8CFga",
        "outputId": "c48b54b6-ab0e-4eae-e880-7b87569327b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1. 1. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Escrever uma conclusão legal, nada de conclusões genéricas (não fazer tipo \"tudo funcionou como esperado\" kkk)\n",
        "# Com a aplicação de um perceptron é possível aplicar funções lógicas de forma escalável, ou seja, em um grande volume de dados."
      ],
      "metadata": {
        "id": "R8YREyVDN_Wl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}